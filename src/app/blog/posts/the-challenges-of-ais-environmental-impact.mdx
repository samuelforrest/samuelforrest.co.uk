---
title: "The Challenges of AI's Environmental Impact"
publishedAt: "2025-04-25"
summary: "The Hidden Environmental Cost of AI’s Rapid Rise, and how we can solve it."
image: "/images/blog/ai-environment.webp"
---

## AI’s Growing Environmental Impact

AI has revolutionised many industries, boosting productivity and profits. However, its environmental toll is becoming increasingly evident. Based on my reading, here are four major environmental concerns related to AI:

- Microchip production and sourcing
- Electronic waste
- Water usage
- Power usage

The most alarming of these is the energy consumption required to power AI systems. If current trends continue, AI data centres could account for **4–8% of global energy usage by 2030** ([Goldman Sachs](https://www.goldmansachs.com)), with some projections suggesting up to 20% (Article 1).

To put this into context: in 2024, agriculture and transportation together account for only about 5% of global electricity consumption. Much of the electricity used in AI data centres comes from non-renewable sources, significantly contributing to carbon emissions.

For example, a single ChatGPT-3.5 query consumes approximately **10× the energy of a Google search** ([International Energy Agency](https://www.iea.org) & Article 2), averaging roughly **0.01 kWh**. Just 15 queries equals the energy needed to boil 5 litres of water (0.15 kWh). This highlights the potentially unsustainable nature of AI’s widespread use.

Additionally, the number of global data centres has exploded from around 500,000 in 2012 to over 8 million today (Article 2), requiring vast quantities of rare earth materials like silicon and nickel. These are often mined unsustainably, resulting in deforestation and ecosystem damage.

Water consumption is another concern. Data centres use immense amounts of water for cooling. With around 20% of the global population lacking access to clean water, this raises both ethical and environmental questions.

---

## A Possible Solution: Optimising AI Model Efficiency

Though large-scale solutions are currently limited, several strategies show promise.

**Two main techniques to make AI models more efficient are:**

- **Model Pruning** — Removing redundant components and unnecessary parameters during training.
- **Knowledge Distillation** — Teaching smaller models to replicate the behaviour of larger ones, maintaining performance while increasing efficiency.

A strong example is **ChatGPT-4 Mini** from [OpenAI](https://openai.com), which leverages knowledge distillation to deliver comparable capability to larger models while reducing energy consumption and computational requirements.

---

## Personal Reflection

This issue became more personal after a conversation with a friend. Learning about the carbon footprint of AI queries made me reconsider how often I rely on these tools. I now try to be more intentional, choosing simpler searches when appropriate.

For instance, [Microsoft](https://www.microsoft.com) reported a **30% rise in emissions in 2023**, driven partly by AI development, which set them back on their sustainability goals. On the other hand, Apple’s on-device approach to **“Apple Intelligence”** ([Apple](https://www.apple.com)) could reduce environmental impact by minimising the need to send large volumes of data to centralised servers.

---

## Conclusion

AI’s environmental impact is no longer a niche issue — it is central to our digital future. As AI becomes more pervasive, the urgency to make it sustainable grows. AI developers and technology companies should focus on:

- Improving model training and deployment efficiency
- Reducing water and power consumption in data centres
- Integrating carbon impact assessments into business planning

Balancing innovation with sustainability will be one of the defining challenges of the decade ahead.
